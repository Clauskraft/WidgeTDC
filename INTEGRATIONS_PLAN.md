# Integration Plan: Grafana, NocoDB, Firecrawl & Rawgraph

## üéØ Goal
Create a unified strategy for leveraging **Grafana**, **NocoDB**, **Firecrawl**, and **Rawgraph** within the WidgeTDC Enterprise platform to:
- Gain deep observability and monitoring (Grafana)
- Provide low‚Äëcode data management and API exposure (NocoDB)
- Enrich the knowledge base with web‚Äëscraped content (Firecrawl)
- Visualise graph‚Äëstructured data for insights (Rawgraph)

---

## üìä 1. Grafana ‚Äì Observability & Metrics

### Why Grafana?
- Central dashboard for **Prometheus** metrics, **logs**, and **traces**.
- Supports alerts, anomaly detection, and team sharing.
- Native integrations for **PostgreSQL**, **Redis**, **PM2**, and **OpenTelemetry**.

### Integration Steps
| Step | Action | Details |
|------|--------|---------|
| 1Ô∏è‚É£ | **Expose Prometheus metrics** | Add `prom-client` to the backend. Create a `/metrics` endpoint that exports:
- HTTP request latency
- DB query duration (Prisma middleware)
- Redis event bus throughput
- Vector store insert/search latency
| 2Ô∏è‚É£ | **PM2 metrics** | Enable `pm2-god` or `pm2-metrics` to expose process CPU, memory, restarts.
| 3Ô∏è‚É£ | **Log shipping** | Configure Winston to write JSON logs to a file (`logs/app.json`). Use **Grafana Loki** as a Docker service to ingest these logs.
| 4Ô∏è‚É£ | **Docker compose** | Add services:
```yaml
prometheus:
  image: prom/prometheus
  volumes:
    - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
  ports:
    - "9090:9090"

grafana:
  image: grafana/grafana
  depends_on:
    - prometheus
    - loki
  ports:
    - "3000:3000"
  environment:
    - GF_SECURITY_ADMIN_PASSWORD=admin
```
| 5Ô∏è‚É£ | **Grafana dashboards** | Import pre‚Äëbuilt dashboards for:
- Node.js Express metrics (via `node_exporter`)
- PostgreSQL performance (`postgres_exporter`)
- Redis (`redis_exporter`)
- Custom dashboard for **Vector Store** (search latency, insert rate)
| 6Ô∏è‚É£ | **Alerting** | Set alerts for:
- CPU > 80% for > 5m
- DB connection errors
- Vector search latency > 200ms
| 7Ô∏è‚É£ | **Documentation** | Add a section in `ARCHITECTURE.md` under *Observability*.

### Timeline (2‚ÄØweeks)
- Week‚ÄØ1: Add metrics endpoint, configure Loki & Prometheus.
- Week‚ÄØ2: Build dashboards, alerts, and documentation.

---

## üìã 2. NocoDB ‚Äì Low‚Äëcode Data Management & API

### Why NocoDB?
- Turns any **PostgreSQL** schema into a **REST/GraphQL** API instantly.
- Provides a spreadsheet‚Äëlike UI for non‚Äëtechnical users to view/edit data.
- Supports **role‚Äëbased access** and **row‚Äëlevel security**.

### Integration Steps
| Step | Action | Details |
|------|--------|---------|
| 1Ô∏è‚É£ | **Add NocoDB service** | Add to `docker-compose.yml`:
```yaml
nocodb:
  image: nocodb/nocodb:latest
  ports:
    - "8080:8080"
  environment:
    - NC_DB="postgres://widgetdc:widgetdc_dev@postgres:5432/widgetdc"
    - NC_AUTH_JWT_SECRET=${JWT_SECRET}
    - NC_ALLOW_SIGNUP=false
```
| 2Ô∏è‚É£ | **Expose schemas** | NocoDB will auto‚Äëdiscover the Prisma schema. Verify tables: `vector_documents`, `agents`, `memory_entities`, etc.
| 3Ô∏è‚É£ | **Configure RBAC** | Use NocoDB UI to create roles (admin, analyst, viewer). Map to PostgreSQL RLS policies already defined.
| 4Ô∏è‚É£ | **Custom API endpoints** | For vector search, create a **NocoDB custom function** that calls the `PgVectorStoreAdapter.search` via a tiny Node wrapper (exposed as a webhook). This gives a REST endpoint `/api/nc/vector-search`.
| 5Ô∏è‚É£ | **Sync with MCP** | Add a small adapter in `apps/backend/src/services/nocodb/NocoAdapter.ts` that forwards MCP tool calls to NocoDB when needed (e.g., `vidensarkiv.add`).
| 6Ô∏è‚É£ | **Documentation** | Add a *Data Management* section in `README.md` with a quick‚Äëstart guide.

### Timeline (1‚ÄØweek)
- Day‚ÄØ1: Add service, test connection.
- Day‚ÄØ2‚Äë3: Configure RBAC & RLS.
- Day‚ÄØ4‚Äë5: Implement custom vector‚Äësearch webhook.
- Day‚ÄØ6: Write docs.

---

## üåê 3. Firecrawl ‚Äì Web Scraping & Knowledge Enrichment

### Why Firecrawl?
- Provides **headless browser crawling** with **HTML ‚Üí Markdown** conversion.
- Handles JavaScript‚Äëheavy sites, pagination, and rate‚Äëlimiting.
- Returns clean text ready for embedding generation.

### Integration Steps
| Step | Action | Details |
|------|--------|---------|
| 1Ô∏è‚É£ | **Create Firecrawl service** | Add a small Node wrapper `FirecrawlService.ts` that calls the public API (`https://api.firecrawl.dev/v0/crawl`). Store the API key in `.env` (`FIRECRAWL_API_KEY`).
| 2Ô∏è‚É£ | **Ingestion pipeline extension** | Extend `DataIngestionEngine` to accept a **URL** payload. The engine will:
- Call Firecrawl ‚Üí get markdown content.
- Pass content to `EmbeddingService` ‚Üí generate embedding.
- Upsert into `PgVectorStoreAdapter` with metadata `{source: url}`.
| 3Ô∏è‚É£ | **Rate limiting & queue** | Use a **BullMQ** queue (Redis‚Äëbacked) to schedule crawls and avoid hitting API limits.
| 4Ô∏è‚É£ | **Metadata enrichment** | Store crawl timestamp, page title, and raw HTML (optional) in a new table `web_pages` (add to Prisma schema).
| 5Ô∏è‚É£ | **MCP tool** | Add a new tool `web.crawlAndIngest` in `mcpRouter.ts` that triggers the above flow.
| 6Ô∏è‚É£ | **UI widget** | Create a new widget `WebCrawlerWidget` on the dashboard allowing users to input URLs and view crawl status.
| 7Ô∏è‚É£ | **Documentation** | Add a *Web Enrichment* section in `SEMANTIC_SEARCH_GUIDE.md`.

### Timeline (2‚ÄØweeks)
- Week‚ÄØ1: Service wrapper, queue, and schema migration.
- Week‚ÄØ2: MCP tool, widget, and docs.

---

## üìà 4. Rawgraph ‚Äì Graph Visualisation

### Why Rawgraph?
- Open‚Äësource visualisation tool for **network/graph data**.
- Accepts CSV/JSON and produces interactive SVG/HTML visualisations.
- Perfect for visualising the **knowledge graph** (`Neo4jGraphAdapter`).

### Integration Steps
| Step | Action | Details |
|------|--------|---------|
| 1Ô∏è‚É£ | **Deploy Rawgraph** | Add a Docker service:
```yaml
rawgraph:
  image: rawgraph/rawgraph:latest
  ports:
    - "8081:8080"
```
| 2Ô∏è‚É£ | **Export graph data** | Implement an endpoint `/api/graph/export` that returns **CSV** with columns `source,target,weight` from Neo4j (or from `memory_entities` relationships).
| 3Ô∏è‚É£ | **Import into Rawgraph** | Users can open Rawgraph UI, load the CSV via URL (`http://localhost:8081/data.csv`).
| 4Ô∏è‚É£ | **Embedding‚Äëdriven edges** | After a semantic search, generate a **sub‚Äëgraph** of top‚ÄëN related entities and feed it to Rawgraph for visual exploration.
| 5Ô∏è‚É£ | **Widget integration** | Add a `GraphViewerWidget` that embeds Rawgraph via an `<iframe>` pointing to the service with the generated CSV URL.
| 6Ô∏è‚É£ | **Documentation** | Add a *Graph Visualisation* chapter in `ARCHITECTURE.md` and a quick‚Äëstart in `QUICK_START.md`.

### Timeline (1‚ÄØweek)
- Day‚ÄØ1‚Äë2: Deploy Rawgraph, create export endpoint.
- Day‚ÄØ3‚Äë4: Build widget and iframe integration.
- Day‚ÄØ5: Write docs and demo screenshots.

---

## üìÖ Overall Roadmap (4‚ÄØweeks total)
| Week | Focus |
|------|-------|
| 1 | Grafana metrics, Prometheus & Loki setup.
| 2 | Grafana dashboards, alerts, and documentation.
| 3 | NocoDB service, RBAC, and vector‚Äësearch webhook.
| 4 | Firecrawl integration + Rawgraph visualisation (parallel work).

## üìå Deliverables
- **Docker compose** updates with new services.
- **Environment variables** (`FIRECRAWL_API_KEY`, `GRAFANA_ADMIN_PASSWORD`).
- **Updated Prisma schema** (`web_pages` table).
- **New source files**:
  - `apps/backend/src/services/web/FirecrawlService.ts`
  - `apps/backend/src/services/nocodb/NocoAdapter.ts`
  - `apps/backend/src/services/graph/GraphExportController.ts`
  - `apps/backend/src/widgets/WebCrawlerWidget.tsx`
  - `apps/backend/src/widgets/GraphViewerWidget.tsx`
- **Documentation** updates:
  - `ARCHITECTURE.md` ‚Äì Observability & Integration sections.
  - `QUICK_START.md` ‚Äì New services.
  - `SEMANTIC_SEARCH_GUIDE.md` ‚Äì Firecrawl enrichment.
  - `README.md` ‚Äì NocoDB & Rawgraph quick start.
- **TODO.md** entries for each integration (high‚Äëpriority).

---

## ‚úÖ Success Criteria
- **Grafana** shows real‚Äëtime metrics and alerts without manual config.
- **NocoDB** provides a functional UI for all tables and a working REST endpoint for vector search.
- **Firecrawl** can ingest a URL and make the content searchable within 30‚ÄØseconds.
- **Rawgraph** visualises a sub‚Äëgraph of at least 20 nodes with interactive controls.
- All new services are **docker‚Äëcompose up**‚Äëable and documented.

---

**Next Action:**
1. Add the Docker services to `docker-compose.yml`.
2. Create the new source files (placeholders) and commit.
3. Update `TODO.md` with the tasks above.

Feel free to let me know which integration you‚Äôd like to start with, or if you need any of the placeholder files created now.

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŠ DeepSeek Integration i Google Colab\n",
    "\n",
    "Dette notebook viser hvordan du bruger DeepSeek i Google Colab/Antigravity\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 1: Installer Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenAI SDK (DeepSeek er kompatibel)\n",
    "!pip install openai --quiet\n",
    "print(\"âœ… OpenAI SDK installeret!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”‘ Step 2: Konfigurer API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Din DeepSeek API key\n",
    "DEEPSEEK_API_KEY = \"sk-a3f8e6b48271466b981396dc97fd904a\"\n",
    "\n",
    "# Opret client\n",
    "client = OpenAI(\n",
    "    api_key=DEEPSEEK_API_KEY,\n",
    "    base_url=\"https://api.deepseek.com/v1\"\n",
    ")\n",
    "\n",
    "print(\"âœ… DeepSeek client konfigureret!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Step 3: Simple Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_deepseek(prompt, temperature=0.7, max_tokens=2000):\n",
    "    \"\"\"\n",
    "    Chat med DeepSeek\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Test det\n",
    "response = chat_with_deepseek(\"Hej DeepSeek! Sig hej pÃ¥ dansk.\")\n",
    "print(\"ðŸ¤– DeepSeek:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 4: Praktiske Eksempler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksempel 1: Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = \"\"\"\n",
    "Skriv en Python funktion der:\n",
    "1. Tager en liste af tal\n",
    "2. Fjerner duplikater\n",
    "3. Sorterer listen\n",
    "4. Returnerer resultat\n",
    "\n",
    "Inkluder docstring og type hints.\n",
    "\"\"\"\n",
    "\n",
    "code = chat_with_deepseek(code_prompt, temperature=0.3)\n",
    "print(\"ðŸ’» Genereret kode:\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksempel 2: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prompt = \"\"\"\n",
    "Jeg har fÃ¸lgende data om website traffic:\n",
    "- Mandag: 1500 besÃ¸g\n",
    "- Tirsdag: 1800 besÃ¸g\n",
    "- Onsdag: 1200 besÃ¸g\n",
    "- Torsdag: 2100 besÃ¸g\n",
    "- Fredag: 2500 besÃ¸g\n",
    "\n",
    "Analyser dataen og giv insights pÃ¥ dansk.\n",
    "\"\"\"\n",
    "\n",
    "analysis = chat_with_deepseek(data_prompt)\n",
    "print(\"ðŸ“Š Analyse:\")\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksempel 3: Multi-turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"Du er en hjÃ¦lpsom dansk programmerings-assistent.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hvad er forskellen pÃ¥ list og tuple i Python?\"}\n",
    "]\n",
    "\n",
    "# First message\n",
    "response1 = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=conversation\n",
    ")\n",
    "\n",
    "answer1 = response1.choices[0].message.content\n",
    "print(\"Q1: Hvad er forskellen pÃ¥ list og tuple?\")\n",
    "print(\"A1:\", answer1)\n",
    "print()\n",
    "\n",
    "# Add to conversation\n",
    "conversation.append({\"role\": \"assistant\", \"content\": answer1})\n",
    "conversation.append({\"role\": \"user\", \"content\": \"Kan du give et konkret eksempel?\"})\n",
    "\n",
    "# Second message\n",
    "response2 = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=conversation\n",
    ")\n",
    "\n",
    "answer2 = response2.choices[0].message.content\n",
    "print(\"Q2: Kan du give et konkret eksempel?\")\n",
    "print(\"A2:\", answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 5: Advanced - Stream Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def stream_chat(prompt):\n",
    "    \"\"\"\n",
    "    Stream response fra DeepSeek\n",
    "    \"\"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    print(\"ðŸ¤– DeepSeek (streaming): \", end=\"\")\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\", flush=True)\n",
    "    \n",
    "    print()  # New line\n",
    "\n",
    "# Test streaming\n",
    "stream_chat(\"FortÃ¦l mig en kort historie om en robot der lÃ¦rer at kode.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¨ Step 6: Interactive Chat Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Chat history\n",
    "chat_history = []\n",
    "\n",
    "# UI Components\n",
    "output = widgets.Output()\n",
    "text_input = widgets.Textarea(\n",
    "    placeholder='Skriv din besked...',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "send_button = widgets.Button(\n",
    "    description='Send til DeepSeek',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "clear_button = widgets.Button(\n",
    "    description='Ryd chat',\n",
    "    button_style='warning',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "def send_message(b):\n",
    "    user_message = text_input.value\n",
    "    if not user_message.strip():\n",
    "        return\n",
    "    \n",
    "    # Add user message\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    # Get response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=chat_history\n",
    "    )\n",
    "    \n",
    "    assistant_message = response.choices[0].message.content\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    \n",
    "    # Display\n",
    "    with output:\n",
    "        clear_output()\n",
    "        for msg in chat_history:\n",
    "            if msg[\"role\"] == \"user\":\n",
    "                display(Markdown(f\"**ðŸ‘¤ Du:** {msg['content']}\"))\n",
    "            else:\n",
    "                display(Markdown(f\"**ðŸ¤– DeepSeek:** {msg['content']}\"))\n",
    "            print(\"---\")\n",
    "    \n",
    "    # Clear input\n",
    "    text_input.value = \"\"\n",
    "\n",
    "def clear_chat(b):\n",
    "    global chat_history\n",
    "    chat_history = []\n",
    "    with output:\n",
    "        clear_output()\n",
    "        display(Markdown(\"*Chat ryddet. Start en ny samtale!*\"))\n",
    "\n",
    "send_button.on_click(send_message)\n",
    "clear_button.on_click(clear_chat)\n",
    "\n",
    "# Display UI\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2>ðŸŒŠ Chat med DeepSeek</h2>\"),\n",
    "    output,\n",
    "    text_input,\n",
    "    widgets.HBox([send_button, clear_button])\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 7: Token Usage & Cost Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_stats(prompt):\n",
    "    \"\"\"\n",
    "    Chat og vis token statistik\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-chat\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    content = response.choices[0].message.content\n",
    "    usage = response.usage\n",
    "    \n",
    "    # DeepSeek pricing (per 1M tokens)\n",
    "    input_cost = 0.27\n",
    "    output_cost = 1.1\n",
    "    \n",
    "    total_cost = (\n",
    "        (usage.prompt_tokens / 1_000_000) * input_cost +\n",
    "        (usage.completion_tokens / 1_000_000) * output_cost\n",
    "    )\n",
    "    \n",
    "    print(\"ðŸ¤– DeepSeek:\", content)\n",
    "    print()\n",
    "    print(\"ðŸ“Š Statistik:\")\n",
    "    print(f\"  Input tokens: {usage.prompt_tokens:,}\")\n",
    "    print(f\"  Output tokens: {usage.completion_tokens:,}\")\n",
    "    print(f\"  Total tokens: {usage.total_tokens:,}\")\n",
    "    print(f\"  ðŸ’° Estimated cost: ${total_cost:.6f}\")\n",
    "\n",
    "# Test\n",
    "chat_with_stats(\"Forklar machine learning pÃ¥ dansk i 3 sÃ¦tninger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Du er klar!\n",
    "\n",
    "Nu kan du bruge DeepSeek i Google Colab/Antigravity!\n",
    "\n",
    "### NÃ¦ste skridt:\n",
    "- Eksperimenter med forskellige prompts\n",
    "- PrÃ¸v forskellige temperature settings\n",
    "- Byg din egen chat application\n",
    "- Integrer med dine data\n",
    "\n",
    "**Tips:**\n",
    "- DeepSeek er sÃ¦rligt god til coding tasks\n",
    "- Brug lav temperature (0.3) for code generation\n",
    "- Brug hÃ¸j temperature (0.8) for kreativt indhold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
